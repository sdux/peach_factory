{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV - version:  4.0.0\n"
     ]
    }
   ],
   "source": [
    "# Packages\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "print('OpenCV - version: ',cv2.__version__)\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found:  579 json keypoint frame files\n",
      "json files:  squat_front_trim_000000000000_keypoints.json\n",
      "Bad point file:  squat_front_trim_000000000570_keypoints.json\n",
      "length of merged keypoint set:  43425\n",
      "        x      y  acc\n",
      "0  1208.0  777.0  0.0\n",
      "1  1208.0  777.0  0.0\n",
      "2  1208.0  785.0  0.0\n",
      "3  1209.0  777.0  0.0\n",
      "4  1209.0  777.0  0.0\n",
      "        x      y  acc\n",
      "0  1010.0  785.0  0.0\n",
      "1  1010.0  785.0  0.0\n",
      "2  1018.0  785.0  0.0\n",
      "3  1018.0  785.0  0.0\n",
      "4  1010.0  785.0  0.0\n"
     ]
    }
   ],
   "source": [
    "# Load keypoint data from JSON output\n",
    "    \n",
    "column_names = ['x', 'y', 'acc']\n",
    "path_to_json = \"output/squat_front/\"\n",
    "json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n",
    "print('Found: ',len(json_files),'json keypoint frame files')\n",
    "\n",
    "body_keypoints_df = pd.DataFrame()\n",
    "left_knee_df = pd.DataFrame()\n",
    "right_knee_df = pd.DataFrame()\n",
    "knee_sep_df = pd.DataFrame()\n",
    "mid_hip_df = pd.DataFrame()\n",
    "\n",
    "print('json files: ',json_files[0])   \n",
    "\n",
    "\n",
    "#Loop through all json files in output directory\n",
    "for file in json_files:\n",
    "    try:\n",
    "        temp_df = pd.read_json(path_to_json+file, orient='record')\n",
    "        temp_df = pd.DataFrame.from_dict(temp_df.values[0][0], orient='index')\n",
    "        \n",
    "    except:\n",
    "        print('Bad point file: ', file)\n",
    "    \n",
    "    body_keypoints_df= body_keypoints_df.append(temp_df)\n",
    "    left_knee_df = left_knee_df.append(temp_df.iloc[13].astype(int))\n",
    "    right_knee_df = right_knee_df.append(temp_df.iloc[10].astype(int))\n",
    "    mid_hip_df = mid_hip_df.append(temp_df.iloc[8].astype(int))\n",
    "    knee_sep_df = knee_sep_df.append(temp_df.iloc[13]-temp_df.iloc[10], ignore_index=True)\n",
    "\n",
    "body_keypoints_df.head()\n",
    "body_keypoints_df.columns = column_names\n",
    "left_knee_df.columns = column_names\n",
    "right_knee_df.columns = column_names\n",
    "mid_hip_df.columns = column_names\n",
    "\n",
    "body_keypoints_df.reset_index()\n",
    "right_knee_df = right_knee_df.reset_index(drop = True)\n",
    "left_knee_df = left_knee_df.reset_index(drop = True)\n",
    "mid_hip_df = mid_hip_df.reset_index(drop=True)\n",
    "print('length of merged keypoint set: ',body_keypoints_df.size)\n",
    "\n",
    "print(left_knee_df.head())\n",
    "print(right_knee_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate motion flags (ascending vs decending)\n",
    "def calc_y_gradients(points):\n",
    "    points['gradient'] = 0\n",
    "    grad_calc = []\n",
    "    cur = 5\n",
    "    prev = 5\n",
    "    \n",
    "    for pt in range(0,len(points)):\n",
    "        if pt > 10:\n",
    "            # subtract current y coordinate from previous y coordinate\n",
    "            # positive values are moving down in the video (bottom of screen is larger number)\n",
    "            # negative points moving up\n",
    "      \n",
    "            grad = np.mean(points['y'].values[pt-cur:pt]) - np.mean(points['y'].values[pt-(cur+prev):pt-cur])\n",
    "            #print('Grad num: ',grad)\n",
    "            \n",
    "            if grad > 0:\n",
    "                grad_calc.append(1)\n",
    "            elif grad < 0:\n",
    "                grad_calc.append(-1)\n",
    "            else:\n",
    "                grad_calc.append(0)\n",
    "        else:\n",
    "            grad_calc.append(0)\n",
    "        # Now we need to store the gradient data in the points dataframe\n",
    "    print('length of grad calc, ', len(grad_calc))\n",
    "    print('length of points, ', len(points))\n",
    "    points['gradient'] = grad_calc\n",
    "    \n",
    "    # return updated points set with gradient column\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pt_delta(points, cntr_y, cntr_x):\n",
    "    points['delta'] = 0\n",
    "    delta_calc = []\n",
    "    delta_previous = 0\n",
    "    delta_previous_x = 0\n",
    "    delta_previous_y = 0\n",
    "    # scalars to set windows of frames to average position\n",
    "    cur = 5\n",
    "    prev = 10\n",
    "    \n",
    "    for pt in range(0, len(points)):\n",
    "        # discard the first set of points (arbitrary, assuming consistent motion is not\n",
    "        # occuring in opening few frames)\n",
    "        if pt > 20:\n",
    "            # calculate the delta between the current position and \n",
    "            # a reference point based on the person's starting position\n",
    "            delta_x = np.abs(np.mean(points['x'].values[pt-cur:pt]) - cntr_x)\n",
    "            delta_y = np.abs(np.mean(points['y'].values[pt-cur:pt]) - cntr_y)\n",
    "            delta_previous_x = np.abs( np.mean(points['x'].values[pt-(cur+prev):pt-cur])- cntr_x)\n",
    "            delta_previous_y = np.abs( np.mean(points['y'].values[pt-(cur+prev):pt-cur]) - cntr_y)\n",
    "            delta = int(np.sqrt(delta_x*delta_x + delta_y*delta_y))\n",
    "            delta_previous = int(np.sqrt(delta_previous_x*delta_previous_x +\n",
    "                                         delta_previous_y*delta_previous_y))\n",
    "            \n",
    "            if delta > delta_previous+2:\n",
    "                delta_calc.append(1)\n",
    "                delta_previous = delta\n",
    "            elif delta < delta_previous-2:\n",
    "                delta_calc.append(-1)\n",
    "                delta_previous = delta\n",
    "            else:\n",
    "                delta_calc.append(0)\n",
    "        else:\n",
    "            delta_calc.append(0)\n",
    "                \n",
    "    print('Length of delta calc: ', len(delta_calc))\n",
    "    points['delta'] = delta_calc\n",
    "    \n",
    "    return points\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_knee_disp(pts_l,pts_r, cntr_y, cntr_x):\n",
    "    pts_l['knee_delta'] = 0\n",
    "    pts_r['knee_delta'] = 0\n",
    "    delta_r_flags = []\n",
    "    delta_l_flags = []\n",
    "    delta_calc = []\n",
    "\n",
    "    for pt in range(0, len(pts_r)):\n",
    "        # calculate the delta between the current position and \n",
    "        # a reference point based on the person's starting position\n",
    "        mid_x = int((pts_r['x'].values[pt] + pts_l['x'].values[pt])/2)\n",
    "        delta = mid_x - centr_x\n",
    "        delta_calc.append(delta)\n",
    "                \n",
    "    print('Length of delta calc: ', len(delta_calc))\n",
    "    pts_l['knee_delta'] = delta_calc\n",
    "    pts_r['knee_delta'] = delta_calc\n",
    "    \n",
    "    knee_delta_mean = np.mean(np.absolute(pts_r['knee_delta'].values))\n",
    "    \n",
    "    for pt in range(0, len(pts_r)):\n",
    "        if np.absolute(pts_l['knee_delta'].values[pt]) > (1.30*knee_delta_mean):\n",
    "            if pts_l['knee_delta'].values[pt] > 0:\n",
    "                delta_r_flags.append(1)\n",
    "                \n",
    "            else:\n",
    "                delta_l_flags.append(1)\n",
    "                \n",
    "                \n",
    "    pts_l['knee_flags'] = delta_l_flags\n",
    "    pts_r['knee_flags'] = delta_r_flags\n",
    "    \n",
    "    return pts_l, pts_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Auto classify motion - expected vs anomalous\n",
    "pt = 5\n",
    "grad = left_knee_df['y'].values[pt] - left_knee_df['y'].values[pt-1]\n",
    "print(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create connected poly ID\n",
    "def poly_id(points):\n",
    "    points['polyid'] = 0\n",
    "    id_var = 'gradient'\n",
    "    #id_var = 'delta'\n",
    "    grad_status = 0\n",
    "    delta_status = 0\n",
    "    id_num = 0\n",
    "    poly_calc = []\n",
    "    \n",
    "    for pt in range(0,len(points)):\n",
    "       \n",
    "        if grad_status == points[id_var].values[pt]:\n",
    "            poly_calc.append(id_num)\n",
    "        else:\n",
    "            grad_status = points[id_var].values[pt]\n",
    "            id_num += 1\n",
    "            poly_calc.append(id_num)\n",
    "            \n",
    "    points['polyid'] = poly_calc\n",
    "    \n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create connected poly ID\n",
    "def delta_id(points):\n",
    "    points['delta_id'] = 0\n",
    "    #id_var = 'gradient'\n",
    "    id_var = 'delta'\n",
    "    grad_status = 0\n",
    "    delta_status = 0\n",
    "    id_num = 0\n",
    "    poly_calc = []\n",
    "    \n",
    "    for pt in range(0,len(points)):\n",
    "       \n",
    "        if grad_status == points[id_var].values[pt]:\n",
    "            poly_calc.append(id_num)\n",
    "        else:\n",
    "            grad_status = points[id_var].values[pt]\n",
    "            id_num += 1\n",
    "            poly_calc.append(id_num)\n",
    "            \n",
    "    points['delta_id'] = poly_calc\n",
    "    \n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create connected poly ID\n",
    "def create_pos_id(points, id_var = 'position'):\n",
    "    col_name = id_var+'_id'\n",
    "    points[col_name] = 0\n",
    "    #id_var = 'gradient'\n",
    "    status = 0\n",
    "    id_num = 0\n",
    "    poly_calc = []\n",
    "    \n",
    "    for pt in range(0,len(points)):\n",
    "       \n",
    "        if status == points[id_var].values[pt]:\n",
    "            poly_calc.append(id_num)\n",
    "        else:\n",
    "            status = points[id_var].values[pt]\n",
    "            id_num += 1\n",
    "            poly_calc.append(id_num)\n",
    "            \n",
    "    points[col_name] = poly_calc\n",
    "    \n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate motion flags (ascending vs decending)\n",
    "def motion(pts):\n",
    "    column_name = 'motion'\n",
    "    pts[column_name] = 0\n",
    "    motion_calc = []\n",
    "    seg_num = max(pts['position_id'].values)\n",
    "    print('seg num ', seg_num)\n",
    "    max_y = 0\n",
    "    seg = 0\n",
    "    for seg in range(0,seg_num):\n",
    "        \n",
    "        seg_pts = pts[pts['position_id']==seg]\n",
    "        if len(seg_pts) > 0:\n",
    "            print('Number of segment points: ',len(seg_pts))\n",
    "            max_y = max(seg_pts['y'].values)\n",
    "            min_y = min(seg_pts['y'].values)\n",
    "            \n",
    "            #print(pts.loc[(pts[\"position_id\"] == seg) & (pts[\"y\"] == max_y), \"motion\"])\n",
    "            \n",
    "            # Check position values for given segment\n",
    "            # Position < 0 means we're at the bottom of te motion\n",
    "            # Bottom of the motion means we'll be finding the point at which we start to move up\n",
    "            # to find the bottom of the range of motion we look for the largest y value\n",
    "            # we'll assign '1' to that point because we'll be moving up after that point.\n",
    "            \n",
    "            if seg_pts['position'].values[0] < 0:\n",
    "                query_motion = pts.query('position_id == @seg & y == @max_y').index\n",
    "                pts.at[query_motion[0], 'motion'] = 1\n",
    "            \n",
    "            elif seg_pts['position'].values[0] > 0:\n",
    "                query_motion = pts.query('position_id == @seg & y == @min_y').index\n",
    "                pts.at[query_motion[0], 'motion'] = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create connected poly ID\n",
    "def motion_id(points):\n",
    "    column_name = 'motion_id'\n",
    "    motion_calc = []\n",
    "    # higher y values correspond to the lower part of the image\n",
    "    # standing upright ~ lower y coordinate value\n",
    "    \n",
    "    last = 0\n",
    "    direction = 'down'\n",
    "    cur = 0\n",
    "    \n",
    "    for pt in range(0,len(points)):\n",
    "        cur = points['motion'].values[pt]\n",
    "        \n",
    "        if cur > 0:\n",
    "            direction = 'up'\n",
    "            motion_calc.append(direction)\n",
    "        elif cur < 0:\n",
    "            direction = 'down'\n",
    "            motion_calc.append(direction)\n",
    "        else:\n",
    "            motion_calc.append(direction)\n",
    "            \n",
    "    # Now we need to store the position data in the points dataframe\n",
    "    points[column_name] = motion_calc\n",
    "    \n",
    "    print(points.head())\n",
    "    \n",
    "    # return updated points set with gradient column\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate position flags (upper vs lower)\n",
    "# current position is > than mid point ~ assign -1 --> indicates bottom half of motion range\n",
    "# current position is < than mid point ~ assign 1 --> indicates top half of motion range\n",
    "\n",
    "def position(points):\n",
    "    column_name = 'position'\n",
    "    points[column_name] = 0\n",
    "    motion_calc = []\n",
    "    # higher y values correspond to the lower part of the image\n",
    "    # standing upright ~ lower y coordinate value\n",
    "    pos_min = np.max(points['y'].values)\n",
    "    pos_max = np.min(points['y'].values)\n",
    "\n",
    "    mid_pt = int((pos_min+pos_max) / 2)\n",
    "    cur = 0\n",
    "    \n",
    "    for pt in range(0,len(points)):\n",
    "        cur = points['y'].values[pt]\n",
    "        if cur > mid_pt:\n",
    "            motion_calc.append(-1)\n",
    "        elif cur < mid_pt:\n",
    "            motion_calc.append(1)\n",
    "        else:\n",
    "            motion_calc.append(0)\n",
    "            \n",
    "    # Now we need to store the position data in the points dataframe\n",
    "    points[column_name] = motion_calc\n",
    "    \n",
    "    # return updated points set with gradient column\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create connected poly ID\n",
    "def motion_id_seg(points, id_var = 'motion_id'):\n",
    "    col_name = id_var+'_seg'\n",
    "    points[col_name] = 0\n",
    "    #id_var = 'gradient'\n",
    "    status = 0\n",
    "    id_num = 0\n",
    "    poly_calc = []\n",
    "    \n",
    "    for pt in range(0,len(points)):\n",
    "       \n",
    "        if status == points[id_var].values[pt]:\n",
    "            poly_calc.append(id_num)\n",
    "        else:\n",
    "            status = points[id_var].values[pt]\n",
    "            id_num += 1\n",
    "            poly_calc.append(id_num)\n",
    "            \n",
    "    points[col_name] = poly_calc\n",
    "    \n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of grad calc,  579\n",
      "length of points,  579\n",
      "length of grad calc,  579\n",
      "length of points,  579\n",
      "length of grad calc,  579\n",
      "length of points,  579\n",
      "Length of delta calc:  579\n",
      "Length of delta calc:  579\n",
      "seg num  9\n",
      "Number of segment points:  60\n",
      "Number of segment points:  66\n",
      "Number of segment points:  103\n",
      "Number of segment points:  49\n",
      "Number of segment points:  104\n",
      "Number of segment points:  32\n",
      "Number of segment points:  101\n",
      "Number of segment points:  36\n",
      "        x      y  acc  gradient  position  position_id  motion motion_id\n",
      "0  1114.0  544.0  0.0         0         1            1       0      down\n",
      "1  1122.0  544.0  0.0         0         1            1       0      down\n",
      "2  1122.0  535.0  0.0         0         1            1       0      down\n",
      "3  1122.0  527.0  0.0         0         1            1      -1      down\n",
      "4  1130.0  527.0  0.0         0         1            1       0      down\n",
      "\n",
      "# of Segment ids: \n",
      "Right Knee Seg ID Gradient:  61\n",
      "Right Knee Seg ID Deltas:  54\n",
      "Mid Hip Seg ID Gradient:  53\n",
      "Mid Hip Seg ID Position_id:  9\n",
      "Ok great, now to correctly identify the top and bottom of the motion\n",
      "        x      y  acc  gradient  position  position_id  motion motion_id  \\\n",
      "0  1114.0  544.0  0.0         0         1            1       0      down   \n",
      "1  1122.0  544.0  0.0         0         1            1       0      down   \n",
      "2  1122.0  535.0  0.0         0         1            1       0      down   \n",
      "3  1122.0  527.0  0.0         0         1            1      -1      down   \n",
      "4  1130.0  527.0  0.0         0         1            1       0      down   \n",
      "\n",
      "   motion_id_seg  polyid  \n",
      "0              1       0  \n",
      "1              1       0  \n",
      "2              1       0  \n",
      "3              1       0  \n",
      "4              1       0  \n"
     ]
    }
   ],
   "source": [
    "# Calculate gradients for points sets.\n",
    "\n",
    "left_knee_df = calc_y_gradients(left_knee_df)\n",
    "right_knee_df = calc_y_gradients(right_knee_df)\n",
    "mid_hip_df = calc_y_gradients(mid_hip_df)\n",
    "\n",
    "cntr_y = int((left_knee_df['y'].values[0] + right_knee_df['y'].values[0]) / 2)\n",
    "cntr_x = int((left_knee_df['x'].values[0] + right_knee_df['x'].values[0]) / 2)\n",
    "\n",
    "left_knee_df = calc_pt_delta(left_knee_df, cntr_y, cntr_x)\n",
    "rigth_knee_df = calc_pt_delta(right_knee_df, cntr_y, cntr_x)\n",
    "\n",
    "# Knee out of position flag section\n",
    "\n",
    "# Direction of motion / rep calculation\n",
    "mid_hip_df = position(mid_hip_df)\n",
    "mid_hip_df = create_pos_id(mid_hip_df, 'position')\n",
    "motion(mid_hip_df)\n",
    "mid_hip_df = motion_id(mid_hip_df)\n",
    "mid_hip_df = motion_id_seg(mid_hip_df)\n",
    "\n",
    "# assigning motion id's to left/right knee\n",
    "left_knee_df['position_id'] = mid_hip_df['position_id'].values\n",
    "right_knee_df['position_id'] = mid_hip_df['position_id'].values\n",
    "\n",
    "left_knee_df['motion_id_seg'] = mid_hip_df['motion_id_seg'].values\n",
    "right_knee_df['motion_id_seg'] = mid_hip_df['motion_id_seg'].values\n",
    "\n",
    "left_knee_df['motion_id'] = mid_hip_df['motion_id'].values\n",
    "right_knee_df['motion_id'] = mid_hip_df['motion_id'].values\n",
    "\n",
    "\n",
    "\n",
    "left_knee_df = poly_id(left_knee_df)\n",
    "right_knee_df = poly_id(right_knee_df)\n",
    "mid_hip_df = poly_id(mid_hip_df)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "print('right number of pos grad',  len(right_knee_df[right_knee_df.iloc[:,3]>0]))\n",
    "print('right number of neg grad',  len(right_knee_df[right_knee_df.iloc[:,3]<0]))\n",
    "\n",
    "#print(right_knee_df[right_knee_df.iloc[:,3]!=0])\n",
    "#print(right_knee_df[0:20])\n",
    "print('right num of neg delta',  len(right_knee_df[right_knee_df['delta']<0]))\n",
    "print('right num of pos delta',  len(right_knee_df[right_knee_df['delta']>0]))\n",
    "'''\n",
    "left_knee_df = delta_id(left_knee_df)\n",
    "right_knee_df = delta_id(right_knee_df)\n",
    "\n",
    "print('\\n# of Segment ids: ')\n",
    "print('Right Knee Seg ID Gradient: ', right_knee_df['polyid'].nunique())\n",
    "print('Right Knee Seg ID Deltas: ', right_knee_df['delta_id'].nunique())\n",
    "print('Mid Hip Seg ID Gradient: ', mid_hip_df['polyid'].nunique())\n",
    "print('Mid Hip Seg ID Position_id: ', mid_hip_df['position_id'].nunique())\n",
    "print('Ok great, now to correctly identify the top and bottom of the motion')\n",
    "mid_hip_df.reset_index()\n",
    "print(mid_hip_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan to Completion\n",
    "\n",
    "#### End state:\n",
    "1. Continuous color segment for down and up motion of the rep\n",
    "\n",
    "#### Play it out:\n",
    "1. Person will start in the same position they finish\n",
    "2. Each Rep should consist of only 2 segments\n",
    "3. The raw gradient, lightly processed gradient and segment IDs are insufficient\n",
    "4. Likely need to write custom motion processing logic and or filtering functions\n",
    "\n",
    "#### Motion Processing\n",
    "1. A rep will start at the max or within max +- 10%\n",
    "    - Max can be determined by sampling t0 or max\n",
    "    - Min can be sampled by taking the min of the set? (for test purposes yes, reality no - failed attempts)\n",
    "2. <b>Possible steps to measure</b>\n",
    "    - Determine max and min based on ranges within total set\n",
    "    - First Pass: determine areas within 50% of min or max?\n",
    "        - Assign labels as upper and lower\n",
    "        - Assign <b>Position Segment IDs</b> based on upper and lower\n",
    "    - Second Pass: identify the local max and min within each segment\n",
    "        - Assign <b>Motion Segment IDs</b> based on min max within each position segment\n",
    "        - For a given position segment id\n",
    "        - determine the max - set to -1 (down) (fisrt occurence)\n",
    "        - determine the min - set to 1 (up) (first occurence)\n",
    "            - challenge will be to correctly assign back to original df?\n",
    "            - all other values \n",
    "        - \n",
    "\n",
    "#### Filtering Funcs\n",
    "1. Smoothing\n",
    "- Total number of segments should be equal to 2x reps\n",
    "- Rep is measured as starting from max - returning to max\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot raw points at every graident change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of x  418\n",
      "length of y  418\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~aduxbury/2.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plotly Plot\n",
    "\n",
    "### TO DO - sub set the plot where gradient not equal zero, add transparency to points, should be good.\n",
    "\n",
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='aduxbury', api_key='1vW1xxY8a14YJ6cd5Efw')\n",
    "trace0 = go.Scatter(\n",
    "    x = left_knee_df.loc[left_knee_df['gradient'] != 0, 'x'],\n",
    "    y = left_knee_df.loc[left_knee_df['gradient'] != 0, 'y'],\n",
    "    mode = 'markers',\n",
    "    name = 'Left Knee',\n",
    "    marker=dict(\n",
    "        size=8,\n",
    "        color = left_knee_df.loc[left_knee_df['gradient'] != 0, 'gradient'], #set color equal to a variable\n",
    "        colorscale='RdBu',\n",
    "        showscale=True\n",
    "    )\n",
    ")\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    x = right_knee_df.loc[right_knee_df['gradient'] != 0, 'x'],\n",
    "    y = right_knee_df.loc[right_knee_df['gradient'] != 0, 'y'],\n",
    "    mode = 'markers',\n",
    "    name = 'Right Knee',\n",
    "    marker=dict(\n",
    "        size=8,\n",
    "        color = right_knee_df.loc[right_knee_df['gradient'] != 0, 'gradient'], #set color equal to a variable\n",
    "        colorscale='RdBu',\n",
    "        showscale=True),\n",
    ")\n",
    "\n",
    "\n",
    "trace2 = go.Scatter(\n",
    "    x = mid_hip_df.loc[mid_hip_df['gradient'] != 0, 'x'],\n",
    "    y = mid_hip_df.loc[mid_hip_df['gradient'] != 0, 'y'],\n",
    "    mode = 'markers',\n",
    "    name = 'Mid Hip',\n",
    "    marker=dict(\n",
    "        size=8,\n",
    "        color = mid_hip_df.loc[mid_hip_df['gradient'] != 0, 'gradient'], #set color equal to a variable\n",
    "        colorscale='RdBu',\n",
    "        showscale=True),\n",
    ")\n",
    "\n",
    "x = right_knee_df.loc[right_knee_df['gradient'] != 0, 'x']\n",
    "y = right_knee_df.loc[right_knee_df['gradient'] != 0, 'y']\n",
    "print('length of x ', len(x))\n",
    "print('length of y ', len(y))\n",
    "\n",
    "\n",
    "layout = go.Layout(\n",
    "    yaxis=dict(autorange='reversed'))\n",
    "    \n",
    "data = [trace0, trace1, trace2]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "\n",
    "py.iplot(fig, filename = 'front_squat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of x  398\n",
      "length of y  398\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~aduxbury/2.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plotly Plot\n",
    "\n",
    "### TO DO - sub set the plot where gradient not equal zero, add transparency to points, should be good.\n",
    "plot_var = 'delta'\n",
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='aduxbury', api_key='1vW1xxY8a14YJ6cd5Efw')\n",
    "trace0 = go.Scatter(\n",
    "    x = left_knee_df.loc[left_knee_df[plot_var] != 0, 'x'],\n",
    "    y = left_knee_df.loc[left_knee_df[plot_var] != 0, 'y'],\n",
    "    mode = 'markers',\n",
    "    name = 'Left Knee',\n",
    "    marker=dict(\n",
    "        size=8,\n",
    "        color = left_knee_df.loc[left_knee_df[plot_var] != 0, plot_var], #set color equal to a variable\n",
    "        colorscale='RdBu',\n",
    "        showscale=True\n",
    "    )\n",
    ")\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    x = right_knee_df.loc[right_knee_df[plot_var] != 0, 'x'],\n",
    "    y = right_knee_df.loc[right_knee_df[plot_var] != 0, 'y'],\n",
    "    mode = 'markers',\n",
    "    name = 'Right Knee',\n",
    "    marker=dict(\n",
    "        size=8,\n",
    "        color = right_knee_df.loc[right_knee_df[plot_var] != 0, plot_var], #set color equal to a variable\n",
    "        colorscale='RdBu',\n",
    "        showscale=True),\n",
    ")\n",
    "x = right_knee_df.loc[right_knee_df[plot_var] != 0, 'x']\n",
    "y = right_knee_df.loc[right_knee_df[plot_var] != 0, 'y']\n",
    "\n",
    "\n",
    "print('length of x ', len(x))\n",
    "print('length of y ', len(y))\n",
    "layout = go.Layout(\n",
    "    yaxis=dict(autorange='reversed'))\n",
    "    \n",
    "data = [trace0, trace1]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "\n",
    "py.iplot(fig, filename = 'front_squat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot histragram of segment 'lengths'\n",
    "Ideally there should be 1 seg down, 1 seg up for each 'rep' in the exercise, but due to sampling that does not occur\n",
    "Gradient changes occur when points are sampled at different grid position, graident changes truncate segments\n",
    "Back and forth changes in gradients create an abundance of short segments (~50 segments with fewer than 10 points)\n",
    "#### Now that a graph has been made, we've #datascienced so, this work is legit.\n",
    "What we can do (hopefully) is drop every segment with fewer than 10 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of seg:  41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~aduxbury/4.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x = right_knee_df['delta_id'].value_counts()\n",
    "print('Max length of seg: ',np.max(x))\n",
    "data = [go.Histogram(x=x)]\n",
    "\n",
    "py.iplot(data, filename='basic histogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(579, 3)\n",
      "(579, 10)\n",
      "(579, 10)\n"
     ]
    }
   ],
   "source": [
    "# QC point sets against number of frames\n",
    "print(knee_sep_df.shape)\n",
    "print(left_knee_df.shape)\n",
    "print(right_knee_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Func to place text on an image\n",
    "def draw_label(img, text):\n",
    "    font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    scale = 0.8\n",
    "    color = (255,255, 255)\n",
    "    bg_color = (0,0,0)\n",
    "    thickness = cv2.FILLED\n",
    "    margin = 10\n",
    "    \n",
    "    # image dimensions\n",
    "    img_y = img.shape[0]\n",
    "    img_x = img.shape[1]\n",
    "\n",
    "    txt_size = cv2.getTextSize(text, font_face, scale, thickness)\n",
    "\n",
    "    # Set text print position to lower middle of screen\n",
    "    # This takes the image size and text size, then positions the message centered\n",
    "    pos = (int(img_y*0.98), (int(img_x/2) - int((txt_size[0][0])/2)))\n",
    "    \n",
    "    # reverses y,x order for plotting as (x,y)\n",
    "    pos = pos[::-1]\n",
    "    \n",
    "    # define end points for text box\n",
    "    # This is used for printing a bounding box\n",
    "    end_x = pos[0] + txt_size[0][0] + margin\n",
    "    end_y = pos[1] - txt_size[0][1] - margin\n",
    "    \n",
    "    # background rectangle\n",
    "    #cv2.rectangle(img, (pos[0]-margin,pos[1]+margin), (end_x, end_y), bg_color, thickness)\n",
    "    # text\n",
    "    cv2.putText(img, text, pos, font_face, scale, color, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Func to place text on an image\n",
    "#Circle(img, center, radius, color, thickness=1, lineType=8, shift=0)\n",
    "def draw_point(img, point, color_select = (255, 255, 255)):\n",
    "    scale = 0.8\n",
    "    bg_color = (0,0,0)\n",
    "    thickness = 4\n",
    "    radius = 4\n",
    "\n",
    "    pos = (int(point[0]), int(point[1]))\n",
    "    \n",
    "    cv2.circle(img, pos, radius, color_select, thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_poly_line(img, pts, color_select = (255,255,255)):\n",
    "    poly_line_thickness = 2\n",
    "    poly_closed = False\n",
    "    pts = pts[:,0:2]\n",
    "    pts = pts.reshape((-1,1,2))\n",
    "    \n",
    "    cv2.polylines(img, np.int32([pts]), poly_closed, color_select, thickness=poly_line_thickness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take point data grouped by segments and plot individual poly segments\n",
    "\n",
    "def draw_line_set(img, pts, color_select = (220,220,200)):\n",
    "\n",
    "    # Figure out the number of segments\n",
    "    seg_num = np.max(pts['motion_id_seg'].values)\n",
    "    red = (255, 0, 0)\n",
    "    blue = (0, 0, 255)\n",
    "    previous_seg_color = blue\n",
    "\n",
    "    counter = 0\n",
    "    counter2 = 0\n",
    "    seg = 1\n",
    "    #print('length of pts: ', len(pts), ' seg_num, ', seg_num)\n",
    "    \n",
    "    # Plot each segment separately and with it's gradient appropriate color\n",
    "    while seg < seg_num+1:\n",
    "        \n",
    "        seg_pts = pts[pts['motion_id_seg']==seg]\n",
    "        if len(seg_pts) > 0:\n",
    "            # based on histogram of points - we want to drop all short points from plotting\n",
    "            #print('inside for loop: ', len(seg_pts))\n",
    "            #print('Seg ', seg)\n",
    "            if(seg_pts['motion_id'].values[0] == 'up'):\n",
    "                # draw a red line for up\n",
    "                draw_poly_line(img, seg_pts.values, blue)\n",
    "                counter = counter+ 1\n",
    "                previous_seg_color = blue\n",
    "                #print('Total pass through up: ',counter)\n",
    "\n",
    "            elif(seg_pts['motion_id'].values[0] == 'down'):\n",
    "                # draw a blue line for down\n",
    "                draw_poly_line(img, seg_pts.values, red)\n",
    "                previous_seg_color = red\n",
    "                counter2 = counter2 + 1 \n",
    "                #print('length of pts ',len(seg_pts.values))\n",
    "\n",
    "            else:\n",
    "                draw_poly_line(img, seg_pts.values, previous_seg_color)\n",
    "        \n",
    "        seg+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnp.max(left_knee_df['polyid'].values)\\nseg_pts = right_knee_df[right_knee_df['motion_id_seg']<3]\\nprint('counting ', seg_pts['motion_id'].values[0]=='down')\\nprint('counting ', seg_pts.iloc[0:20,6:8])\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "np.max(left_knee_df['polyid'].values)\n",
    "seg_pts = right_knee_df[right_knee_df['motion_id_seg']<3]\n",
    "print('counting ', seg_pts['motion_id'].values[0]=='down')\n",
    "print('counting ', seg_pts.iloc[0:20,6:8])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan to sexy MVP\n",
    "\n",
    "1. Add grey fade + alpha channels for plotting\n",
    "    - want to call point - 90 points primary\n",
    "    - zero to 90 as grey with incremental alpha (place in fnc call)\n",
    "    - White circle on knee point\n",
    "#### 2. Develop flags for knee movements out of alignment\n",
    "    - calc Original (standing) center knees (x-coord) (a)\n",
    "    - for each pair of knee points - calc mid point (x-coord) (b)\n",
    "    - calculate the displacement (+-) from the current (b) to center knees (a)\n",
    "    - Calculate a flag based on % displacement from center (a)\n",
    "    - When the flag is triggered - change display text and corresponding knee color\n",
    "3. Add message for knee out of position\n",
    "4. Clean up code base\n",
    "5. Build tooling to load video in openPose, extract point data, process point data and plot new video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video with Knee Tracking Lines - Testing v2 up/down motion tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f09cc1269307>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'examples\\media\\squat_front_ad_trim.mp4'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mframe_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCAP_PROP_FRAME_COUNT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of frames in video: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mframe_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('examples\\media\\squat_front_ad_trim.mp4')\n",
    "frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "print(\"Number of frames in video: \",frame_count)\n",
    "\n",
    "alpha = 0\n",
    "text = \"Current Frame: \"\n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened()== False): \n",
    "  print(\"Error opening video stream or file\")\n",
    "\n",
    "cv2.namedWindow('Peach Factor',cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "count = 0\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        buffer = frame.copy()\n",
    "        if count > 0:\n",
    "            \n",
    "            if count < 150:\n",
    "                #right_temp_df = right_knee_df.iloc[0:count]\n",
    "                #left_temp_df = left_knee_df.iloc[0:count]\n",
    "                # Expected right knee, red line --> direct of motion is up\n",
    "                draw_line_set(frame, right_knee_df.iloc[0:count])\n",
    "                # Expected left knee, red line --> direct of motion is up\n",
    "                draw_line_set(frame, left_knee_df.iloc[0:count])\n",
    "            \n",
    "            else:\n",
    "                #right_temp_df = right_knee_df.iloc[count-89:count]\n",
    "                #left_temp_df = left_knee_df.iloc[count-89:count]\n",
    "                draw_line_set(frame, right_knee_df.iloc[count-149:count])\n",
    "                # Expected left knee, red line --> direct of motion is up\n",
    "                draw_line_set(frame, left_knee_df.iloc[count-149:count])\n",
    "                #alpha = 1-(count/frame_count)+0.2\n",
    "                \n",
    "                draw_line_set(buffer, right_knee_df.iloc[0:count-149])\n",
    "                # Expected left knee, red line --> direct of motion is up\n",
    "                draw_line_set(buffer, left_knee_df.iloc[0:count-149])\n",
    "            \n",
    "            alpha = 0.3\n",
    "            draw_point(buffer, left_knee_df.iloc[count], (255,255,255))\n",
    "            draw_point(buffer, right_knee_df.iloc[count], (255,255,255))\n",
    "            \n",
    "            draw_label(frame, text+str(count))\n",
    "            #cv2.putText(frame,text,(150,500), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "            \n",
    "            cv2.addWeighted(buffer, alpha, frame, 1 - alpha, 0, frame)\n",
    "            cv2.imshow('Peach Factor',frame)\n",
    "\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "    count+=1\n",
    "     \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video with Knee Points only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b6ef4249b7a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'examples\\media\\squat_front_ad_trim.mp4'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of frames in video: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCAP_PROP_FRAME_COUNT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Check if camera opened successfully\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('examples\\media\\squat_front_ad_trim.mp4')\n",
    "\n",
    "print(\"Number of frames in video: \",cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened()== False): \n",
    "  print(\"Error opening video stream or file\")\n",
    "\n",
    "cv2.namedWindow('Peach Factor',cv2.WINDOW_AUTOSIZE)\n",
    "text = \"Good Form!\"\n",
    "\n",
    "count = 0\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        if count > 2:\n",
    "              \n",
    "            right_temp_df = right_knee_df.iloc[count]\n",
    "            left_temp_df = left_knee_df.iloc[count]\n",
    "            \n",
    "            if right_temp_df['gradient']>0:\n",
    "                draw_point(frame, right_temp_df, (255,0,0))\n",
    "            elif right_temp_df['gradient']<0:\n",
    "                draw_point(frame, right_temp_df, (0,0,255))\n",
    "            if left_temp_df['gradient']>0:\n",
    "                draw_point(frame, left_temp_df, (255,0,0))\n",
    "            elif left_temp_df['gradient']<0:\n",
    "                draw_point(frame, left_temp_df, (0,0,255))    \n",
    "                \n",
    "            #draw_point(frame, left_knee_df.iloc[count])\n",
    "            draw_label(frame, text)\n",
    "            #cv2.putText(frame,text,(150,500), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "            cv2.imshow('Peach Factor',frame)\n",
    "\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "    else:\n",
    "        break\n",
    "    count+=1\n",
    "     \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ok so next steps.\n",
    "# 1. line sets.  Polygone line sets can be determined by creating different polygons each time the gradient changes\n",
    "# 2. Lines can be filtered by length and removed from the plotting func.\n",
    "# 3. Plotting should be adjusted such that the poly line plot call is made separately for each grouping of points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video with Knee Tracking Lines - Testing v1 up/down motion tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frames in video:  579.0\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('examples\\media\\squat_front_ad_trim.mp4')\n",
    "print(\"Number of frames in video: \",cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened()== False): \n",
    "  print(\"Error opening video stream or file\")\n",
    "\n",
    "cv2.namedWindow('Peach Factor',cv2.WINDOW_AUTOSIZE)\n",
    "text = \"This man needs help.\"\n",
    "count = 0\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        if count > 80:\n",
    "            right_temp_df = right_knee_df.iloc[count-80:count]\n",
    "            left_temp_df = left_knee_df.iloc[count-80:count]\n",
    "            # Expected right knee, red line --> direct of motion is up\n",
    "            draw_poly_line(frame, right_temp_df.loc[right_temp_df['gradient'] > 0].values, (255,0,0))\n",
    "            # Expected right knee, blue line --> direct of motion is down\n",
    "            draw_poly_line(frame, right_temp_df.loc[right_temp_df['gradient'] < 0].values, (0,0,255))\n",
    "            \n",
    "            # Expected left knee, red line --> direct of motion is up\n",
    "            draw_poly_line(frame, left_temp_df.loc[left_temp_df['gradient'] > 0].values, (255,0,0))\n",
    "            # Expected left knee, blue line --> direct of motion is down\n",
    "            draw_poly_line(frame, left_temp_df.loc[left_temp_df['gradient'] < 0].values, (0,0,255))\n",
    "            \n",
    "            draw_label(frame, text)\n",
    "            #cv2.putText(frame,text,(150,500), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "            cv2.imshow('Peach Factor',frame)\n",
    "\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "    count+=1\n",
    "     \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video with Knee Tracking Lines - All points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('examples\\media\\squat_front_ad_trim.mp4')\n",
    "print(\"Number of frames in video: \",cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened()== False): \n",
    "  print(\"Error opening video stream or file\")\n",
    "\n",
    "cv2.namedWindow('Peach Factor',cv2.WINDOW_AUTOSIZE)\n",
    "text = \"This man needs help.\"\n",
    "count = 0\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        if count > 2:\n",
    "\n",
    "            draw_poly_line(frame, right_knee_df.iloc[0:count].values)\n",
    "            draw_poly_line(frame, left_knee_df.iloc[0:count].values)\n",
    "            draw_label(frame, text)\n",
    "            #cv2.putText(frame,text,(150,500), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "            cv2.imshow('Peach Factor',frame)\n",
    "\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "    count+=1\n",
    "     \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('examples\\media\\squat_front_ad_trim.mp4')\n",
    "\n",
    "print(\"Number of frames in video: \",cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened()== False): \n",
    "  print(\"Error opening video stream or file\")\n",
    "\n",
    "cv2.namedWindow('Peach Factor',cv2.WINDOW_AUTOSIZE)\n",
    "text = \"This man needs help.\"\n",
    "\n",
    "count = 0\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        \n",
    "        for point in range(0,count):\n",
    "            draw_point(frame, left_knee_df.iloc[point])\n",
    "            draw_point(frame, right_knee_df.iloc[point])\n",
    "        draw_label(frame, text)\n",
    "        #cv2.putText(frame,text,(150,500), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "        cv2.imshow('Peach Factor',frame)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "    count+=1\n",
    "     \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frame.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do\n",
    "# 1. Save a sub set of all left knee, right knee and distance between the two\n",
    "# 2. plot all the points, diff color for left and right\n",
    "# 3. look for outliers\n",
    "# find way to auto-classify\n",
    "# 4. Plot knee points with line back onto video frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasty_file = \"squat_front_trim_000000000570_keypoints.json\"\n",
    "try:\n",
    "    temp_df = pd.read_json(path_to_json+nasty_file, orient='record')\n",
    "    temp_df = pd.DataFrame.from_dict(temp_df.values[0][0], orient='index')\n",
    "except:\n",
    "    print('bad record')\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " cv2.polylines(img,[pts],True,(0,255,255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blue = (255, 0, 0)\n",
    "red = (0, 0, 255)\n",
    "green = (0, 255, 0)\n",
    "violet = (180, 0, 180)\n",
    "yellow = (0, 180, 180)\n",
    "white = (255, 255, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.line(image, (50, 30), (450, 35), blue, thickness=5)\n",
    "cv2.circle(image, (240, 205), 23, red, -1)\n",
    "cv2.rectangle(image, (50, 60), (450, 95), green, -1)\n",
    "cv2.ellipse(image, (250, 150), (80, 20), 5, 0, 360, violet, -1)\n",
    "points = np.array([[[140, 230], [380, 230], [320, 250], [250, 280]]], np.int32)\n",
    "cv2.polylines(image, [points], True, yellow, thickness=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_scale = 1.5\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "# set the rectangle background to white\n",
    "rectangle_bgr = (255, 255, 255)\n",
    "# make a black image\n",
    "img = np.zeros((500, 500, 3))\n",
    "# set some text\n",
    "text = \"Some text in a box!\"\n",
    "# get the width and height of the text box\n",
    "(text_width, text_height) = cv2.getTextSize(text, font, fontScale=font_scale, thickness=1)[0]\n",
    "# set the text start position\n",
    "text_offset_x = 10\n",
    "text_offset_y = img.shape[0] - 25\n",
    "# make the coords of the box with a small padding of two pixels\n",
    "box_coords = ((text_offset_x, text_offset_y), (text_offset_x + text_width - 2, text_offset_y - text_height - 2))\n",
    "cv2.rectangle(img, box_coords[0], box_coords[1], rectangle_bgr, cv2.FILLED)\n",
    "cv2.putText(img, text, (text_offset_x, text_offset_y), font, fontScale=font_scale, color=(0, 0, 0), thickness=1)\n",
    "cv2.imshow(\"A box!\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Size of img: ', img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "// Result for BODY_25 (25 body parts consisting of COCO + foot)\n",
    "// const std::map<unsigned int, std::string> POSE_BODY_25_BODY_PARTS {\n",
    "//     {0,  \"Nose\"},\n",
    "//     {1,  \"Neck\"},\n",
    "//     {2,  \"RShoulder\"},\n",
    "//     {3,  \"RElbow\"},\n",
    "//     {4,  \"RWrist\"},\n",
    "//     {5,  \"LShoulder\"},\n",
    "//     {6,  \"LElbow\"},\n",
    "//     {7,  \"LWrist\"},\n",
    "//     {8,  \"MidHip\"},\n",
    "//     {9,  \"RHip\"},\n",
    "//     {10, \"RKnee\"},\n",
    "//     {11, \"RAnkle\"},\n",
    "//     {12, \"LHip\"},\n",
    "//     {13, \"LKnee\"},\n",
    "//     {14, \"LAnkle\"},\n",
    "//     {15, \"REye\"},\n",
    "//     {16, \"LEye\"},\n",
    "//     {17, \"REar\"},\n",
    "//     {18, \"LEar\"},\n",
    "//     {19, \"LBigToe\"},\n",
    "//     {20, \"LSmallToe\"},\n",
    "//     {21, \"LHeel\"},\n",
    "//     {22, \"RBigToe\"},\n",
    "//     {23, \"RSmallToe\"},\n",
    "//     {24, \"RHeel\"},\n",
    "//     {25, \"Background\"}\n",
    "// };\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmulti-select technique\\ndf.loc[(df[\"B\"] > 50) & (df[\"C\"] == 900), \"A\"] *= 1000\\ndf\\n      A   B    C\\n0     9  40  300\\n1     9  70  700\\n2  5000  70  900\\n3  8000  80  900\\n4     7  50  200\\n5     9  30  900\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "multi-select technique\n",
    "df.loc[(df[\"B\"] > 50) & (df[\"C\"] == 900), \"A\"] *= 1000\n",
    "df\n",
    "      A   B    C\n",
    "0     9  40  300\n",
    "1     9  70  700\n",
    "2  5000  70  900\n",
    "3  8000  80  900\n",
    "4     7  50  200\n",
    "5     9  30  900\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import cv2\n",
    " \n",
    "img = cv2.imread('lena.png')\n",
    " \n",
    "# (1) create a copy of the original:\n",
    "overlay = img.copy()\n",
    "# (2) draw shapes:\n",
    "cv2.circle(overlay, (133, 132), 12, (0, 255, 0), -1)\n",
    "cv2.circle(overlay, (166, 132), 12, (0, 255, 0), -1)\n",
    "# (3) blend with the original:\n",
    "opacity = 0.4\n",
    "cv2.addWeighted(overlay, opacity, img, 1 - opacity, 0, img)\n",
    " \n",
    "# display result (press 'q' to quit):\n",
    "cv2.namedWindow('Transparency')\n",
    "cv2.imshow('Transparency', img)\n",
    "while (cv2.waitKey() & 0xff) != ord('q'): pass\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
